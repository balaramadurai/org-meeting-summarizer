* Org Meeting Summarizer

Record audio meetings directly in Emacs, summarize them using AI, and insert summaries into Org-mode subtreesâ€”all without leaving your editor.

*Supports Google Gemini API and Ollama (local or cloud) with Whisper transcription.*

** Quick Start

*** What You Need

- *Emacs* 26.1+ (with Org-mode)
- *Python* 3.6+
- *ffmpeg* for audio recording
- *For Gemini*: =pip install google-generativeai= and API key from [[https://aistudio.google.com/app/apikey][Google AI Studio]]
- *For Ollama*: =pip install openai-whisper requests= and [[https://ollama.com][Ollama]] installed

*** Five-Minute Setup

1. *Install ffmpeg*:
   #+begin_src sh
   sudo apt-get install ffmpeg  # Ubuntu/Debian
   brew install ffmpeg          # macOS
   #+end_src

2. *Install Python dependencies*:
   #+begin_src sh
   # For Gemini:
   pip install google-generativeai

   # For Ollama (with Whisper transcription):
   pip install openai-whisper requests
   #+end_src

3. *Install the package* using =straight.el=:

   *For Gemini:*
   #+begin_src emacs-lisp
   (use-package org-meeting-summarizer
     :straight (org-meeting-summarizer
                :type git
                :host github
                :repo "balaramadurai/org-meeting-summarizer")
     :config
     (setq org-meeting-summarizer-api-provider "gemini")
     (setq org-meeting-summarizer-api-key "your-gemini-api-key")
     (setq org-meeting-summarizer-model "gemini-2.5-flash"))
   #+end_src

   *For Ollama (local):*
   #+begin_src emacs-lisp
   (use-package org-meeting-summarizer
     :straight (org-meeting-summarizer
                :type git
                :host github
                :repo "balaramadurai/org-meeting-summarizer")
     :config
     (setq org-meeting-summarizer-api-provider "ollama")
     (setq org-meeting-summarizer-model "llama3")  ; or mistral, etc.
     (setq org-meeting-summarizer-ollama-api-base "http://localhost:11434")
     (setq org-meeting-summarizer-whisper-model "base"))  ; tiny, base, small, medium, large
   #+end_src

   *For Ollama Cloud:*
   #+begin_src emacs-lisp
   (use-package org-meeting-summarizer
     :straight (org-meeting-summarizer
                :type git
                :host github
                :repo "balaramadurai/org-meeting-summarizer")
     :config
     (setq org-meeting-summarizer-api-provider "ollama")
     (setq org-meeting-summarizer-model "mistral-large-3:675b-cloud")
     (setq org-meeting-summarizer-ollama-api-base "http://localhost:11434")  ; your cloud URL
     (setq org-meeting-summarizer-api-key "your-ollama-cloud-key")  ; if required
     (setq org-meeting-summarizer-whisper-model "base"))
   #+end_src

4. *Verify setup*:
   #+begin_src emacs-lisp
   M-x eval-expression RET org-meeting-summarizer-api-provider RET
   #+end_src
   Should return ="gemini"= or ="ollama"=.

** Usage

*** Basic Workflow

*Record and Summarize a Meeting*

1. Open an Org-mode file and position your cursor in (or create) a subtree:
   #+begin_src org
   * Team Meeting - 2025-01-15
   #+end_src

2. Run: =M-x org-meeting-summarizer-record-and-summarize=

3. Answer the prompts:
   - *File path*: =~/Documents/meeting_2025-01-15.m4a=
   - *Duration*: =30= (seconds, or =0= for manual stop)
   - *Custom prompt*: Press Enter for default, or enter your own

4. For fixed duration: Emacs counts down and summarizes automatically.
   For manual stop (=0=): Run =M-x org-meeting-summarizer-stop-recording= when done, then summarization happens automatically.

5. The summary appears in your subtree:
   #+begin_src org
   * Team Meeting - 2025-01-15
   **Summary for meeting_2025-01-15.m4a**
   - Date: 2025-01-15
   - Attendees: [detected from audio]
   - Notes: [meeting summary]
   - Action Items: [tasks]
   #+end_src

*Summarize an Existing Recording*

1. Position cursor in an Org-mode subtree
2. Run: =M-x org-meeting-summarizer-in-subtree=
3. Provide the file path (=.m4a=) or folder
4. Summary inserts into your subtree

*View All Summaries in a Buffer*

Run: =M-x org-meeting-summarizer /path/to/file.m4a= or =/path/to/folder/=
Results appear in =*Meeting Summaries*= buffer.

*** Optional: Hydra Menu

For faster access to commands, enable Hydra:

#+begin_src emacs-lisp
(use-package hydra :straight t)

;; In org-meeting-summarizer config:
(global-set-key (kbd "C-c m") 'org-meeting-summarizer-hydra/body)
#+end_src

Then press =C-c m= for:
- =r=: Record and summarize at point
- =s=: Summarize file into subtree
- =p=: Summarize file at point
- =t=: Stop recording
- =q=: Quit

** Customization

All settings can be customized via =M-x customize-group RET org-meeting-summarizer=, or in your config:

#+begin_src emacs-lisp
;; API Provider: "gemini" or "ollama"
(setq org-meeting-summarizer-api-provider "gemini")

;; API Key (required for Gemini, optional for local Ollama)
(setq org-meeting-summarizer-api-key "your-key")

;; Model name
(setq org-meeting-summarizer-model "gemini-2.5-flash")  ; or "llama3", "mistral", etc.

;; Ollama-specific settings
(setq org-meeting-summarizer-ollama-api-base "http://localhost:11434")

;; Whisper model for transcription (used with Ollama)
;; Options: tiny, base, small, medium, large, large-v2, large-v3
(setq org-meeting-summarizer-whisper-model "base")

;; Retry delay on rate limit (seconds)
(setq org-meeting-summarizer-retry-delay 60)

;; Keep temp files after summarization
(setq org-meeting-summarizer-keep-temp-files nil)
#+end_src

*** Whisper Model Selection (for Ollama)

When using Ollama, audio is first transcribed using Whisper. Choose based on your needs:

| Model | Speed | Accuracy | Memory |
|-------+-------+----------+--------|
| tiny | Fastest | Basic | ~1GB |
| base | Fast | Good | ~1GB |
| small | Medium | Better | ~2GB |
| medium | Slow | High | ~5GB |
| large | Slowest | Best | ~10GB |

For CPU-only systems, =tiny= or =base= is recommended.

** Troubleshooting

| Problem | Solution |
|---------+----------|
| =API key is required= | Set =org-meeting-summarizer-api-key= for Gemini. For local Ollama, API key is optional. |
| File not found after recording | Check =*Messages*= buffer. Ensure ffmpeg is installed (=ffmpeg -version=) and output directory is writable. |
| Partial or empty summaries | Test Python script directly (see below). Check API quotas. |
| Rate limit errors | Increase =org-meeting-summarizer-retry-delay= to 60+ seconds. Retries are automatic. |
| =Path does not exist= | Verify the file exists: =ls /path/to/file.m4a=. Check for typos in the path. |
| Hydra menu not showing | Install Hydra: =M-x package-install RET hydra=, or via =straight.el=. |
| Whisper not found | Install with =pip install openai-whisper=. |
| Ollama connection error | Ensure Ollama is running: =ollama serve=. Check API base URL uses =http://= not =https://= for local. |

** Features

- Record audio directly in Emacs with ffmpeg
- Multiple AI providers: Gemini API and Ollama (local or cloud)
- Whisper integration for audio transcription (with Ollama)
- Insert summaries at cursor position or end of subtree
- Support for multiple audio formats: m4a, mp3, wav, ogg, flac
- Automatic Markdown to Org-mode conversion
- Countdown timer during fixed-duration recordings
- Automatic summarization after manual stop
- Custom summarization prompts
- Automatic retry on API rate limits
- Optional Hydra menu for interactive access
- Single file or batch folder processing
- MIT licensed

** Advanced Usage

*** Custom Prompts

Provide a custom prompt to shape how meetings are summarized:

#+begin_src emacs-lisp
(M-x org-meeting-summarizer-record-and-summarize)
;; When prompted for "Custom Prompt", enter:
;; "Summarize this standup: participants, blockers, and next steps"
#+end_src

*** Batch Processing

Summarize a folder of recordings at once:

#+begin_src emacs-lisp
M-x org-meeting-summarizer RET ~/Documents/meetings/ RET
#+end_src

Results appear in =*Meeting Summaries*= buffer.

*** Python Script Standalone

Use the Python script independently:

*With Gemini:*
#+begin_src sh
python3 scripts/summarize_meetings.py "/path/to/meeting.m4a" \
  --api_provider "gemini" \
  --api_key "YOUR_KEY" \
  --model "gemini-2.5-flash" \
  --prompt "Summarize this: attendees, decisions, next steps"
#+end_src

*With Ollama:*
#+begin_src sh
python3 scripts/summarize_meetings.py "/path/to/meeting.m4a" \
  --api_provider "ollama" \
  --model "llama3" \
  --api_base "http://localhost:11434" \
  --whisper_model "base" \
  --prompt "Summarize this: attendees, decisions, next steps"
#+end_src

** Environment Variable Setup (Detailed)

If =(getenv "GEMINI_API_KEY")= returns =nil= in Emacs but =echo $GEMINI_API_KEY= shows your key in the terminal, Emacs isn't inheriting your environment. Fix it:

*** Option 1: exec-path-from-shell (Recommended)

#+begin_src emacs-lisp
(use-package exec-path-from-shell
  :straight t
  :config
  (exec-path-from-shell-initialize))
#+end_src

Then add to =~/.zshenv= (for all sessions):
#+begin_src sh
export GEMINI_API_KEY="your-api-key"
#+end_src

*** Option 2: Set directly in Emacs

#+begin_src emacs-lisp
(setenv "GEMINI_API_KEY" "your-api-key")
#+end_src

*** Option 3: Launch Emacs from terminal

#+begin_src sh
export GEMINI_API_KEY="your-api-key"
emacs
#+end_src

*** Option 4: Set in ~/.zshenv or ~/.bashrc

Add this line:
#+begin_src sh
export GEMINI_API_KEY="your-api-key"
#+end_src

Then source it:
#+begin_src sh
source ~/.zshenv  # or source ~/.bashrc
#+end_src

** API Model Options

The package defaults to =gemini-2.5-flash= (fast, cost-effective). Other options:

- =gemini-2.5-pro=: More powerful, handles complex audio
- =gemini-1.5-flash=: Older, still reliable
- =gemini-1.5-pro=: Slower but highly accurate

Set via:
#+begin_src emacs-lisp
(setq org-meeting-summarizer-model "gemini-2.5-pro")
#+end_src

## Debugging

Enable detailed output by checking these buffers:

- =*Messages*=: Recording progress, file checks, retries
- =*Temp Meeting Summaries*=: Raw output from Python script
- =*Meeting Summaries*=: Formatted summaries for review

Run the Python script directly to isolate issues:

#+begin_src sh
python3 ~/.emacs.d/straight/repos/org-meeting-summarizer/scripts/summarize_meetings.py \
  "/path/to/meeting.m4a" \
  --api_key "YOUR_KEY" \
  --model "gemini-2.5-flash"
#+end_src

** API Provider Support

*** Gemini (Default)

Google's Gemini API offers:
- Direct audio file processing (no transcription step needed)
- Strong audio understanding
- Generous free tier for testing

*** Ollama (Local or Cloud)

Ollama support uses a two-step process:
1. *Whisper* transcribes audio to text
2. *Ollama* summarizes the transcript

Benefits:
- Privacy: Run entirely locally
- Cost: No API costs for local models
- Flexibility: Use any Ollama model (llama3, mistral, etc.)
- Cloud option: Use Ollama cloud for larger models

Note: Whisper runs on CPU by default. For faster transcription, use =tiny= or =base= models.

*** Provider Comparison

| Provider | Audio Support | Transcription | Privacy | Cost |
|----------+---------------+---------------+---------+------|
| Gemini | Direct | Built-in | Cloud | Free tier |
| Ollama Local | Via Whisper | Local Whisper | Full | Free |
| Ollama Cloud | Via Whisper | Local Whisper | Partial | Varies |

*** Future Providers

| Provider | Status | Notes |
|----------+--------+-------|
| Claude | Planned | Anthropic API |
| OpenAI | Planned | GPT-4o with audio |

To help implement support for other providers, see [[https://github.com/balaramadurai/org-meeting-summarizer/issues][GitHub Issues]].

** License & Credits

MIT Licensed. Developed with assistance from Grok (xAI) and Claude (Anthropic).

For issues, contributions, or questions:
- GitHub: [[https://github.com/balaramadurai/org-meeting-summarizer][balaramadurai/org-meeting-summarizer]]
- Email: bala@balaramadurai.net
